{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamcodez/Data-science-tools/blob/main/image_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSM9tTZHR-9v"
      },
      "source": [
        "# Data Augmentation in NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxB4fejMFtys"
      },
      "source": [
        "You can use the following notebook to create new images using Data Augmentation.\n",
        "Note: You can use functions seperately with complete control over all transformation factors, \n",
        "mixing the function implementations rather than linearly using it may give better results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfeZy55j1rKX"
      },
      "source": [
        "https://colab.research.google.com/drive/1a-U-odzlPeTIToPi3IwyFyxjz6d367bM?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7iaK5PNR-9x"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from scipy.ndimage import rotate\n",
        "sns.set(color_codes=True)\n",
        "from skimage.transform import resize, rescale"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHVmRvsJhTiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1f5168-bfdd-4940-d959-b59ae9279689"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSErcjMMR-9y"
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import PIL\n",
        "image_limit = 2500 # change according to ram availiblity\n",
        "image_path = '/content/drive/MyDrive/train/i/'\n",
        "destination_path = '/content/drive/MyDrive/train/i/'\n",
        "image_collection = glob.glob(image_path + '*.png')\n",
        "size = 256\n",
        "images = np.array([np.array(Image.open(img).convert('RGB').resize((size, size), Image.ANTIALIAS)) for img in image_collection])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft0FUdAlZITK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20086fd8-aee5-4ff9-a6c7-2cbf9d6aed9b"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWniTFlwR-90"
      },
      "source": [
        "### Translations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3hLfAKOR-90"
      },
      "source": [
        "def translate(img, direction, shift, roll=True):\n",
        "  assert direction in ['right', 'left', 'down', 'up'], 'Directions should be top|up|left|right'\n",
        "  img = img.copy()\n",
        "  if direction == 'right':\n",
        "      right_slice = img[:, -shift:].copy()\n",
        "      img[:, shift:] = img[:, :-shift]\n",
        "      if roll:\n",
        "          img[:,:shift] = np.fliplr(right_slice)\n",
        "  if direction == 'left':\n",
        "      left_slice = img[:, :shift].copy()\n",
        "      img[:, :-shift] = img[:, shift:]\n",
        "      if roll:\n",
        "          img[:, -shift:] = left_slice\n",
        "  if direction == 'down':\n",
        "      down_slice = img[-shift:, :].copy()\n",
        "      img[shift:, :] = img[:-shift,:]\n",
        "      if roll:\n",
        "          img[:shift, :] = down_slice\n",
        "  if direction == 'up':\n",
        "      upper_slice = img[:shift, :].copy()\n",
        "      img[:-shift, :] = img[shift:, :]\n",
        "      if roll:\n",
        "          img[-shift:,:] = upper_slice   \n",
        "  return img    "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjEgWz8talkw"
      },
      "source": [
        "shift = 10\n",
        "translated_images = []\n",
        "directions = ['right', 'left', 'down', 'up']\n",
        "skip_factor = 1\n",
        "i = 1\n",
        "for direction in directions:\n",
        "  for img in images:\n",
        "    if i % skip_factor == 0:\n",
        "      translated_images.append(translate(img,direction,shift))\n",
        "    i = i + 1  "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQas0behiytb"
      },
      "source": [
        "translated_images = np.asarray(translated_images) \n",
        "#translated_images.shape\n",
        "if images.shape[0] +translated_images.shape[0] < image_limit:\n",
        "  images = np.concatenate( (images, translated_images) )  "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55Io2XEmSSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56482daa-996f-4c9e-fe70-88b1ca910d28"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCzSdCYKR-91"
      },
      "source": [
        "def random_crop(img, crop_size=(10, 10)):\n",
        "    assert crop_size[0] <= img.shape[0] and crop_size[1] <= img.shape[1], \"Crop size should be less than image size\"\n",
        "    img = img.copy()\n",
        "    w, h = img.shape[:2]\n",
        "    x, y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
        "    img = img[y:y+crop_size[0], x:x+crop_size[1]]\n",
        "    return img"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTKxJYJ0OUGz"
      },
      "source": [
        "import cv2\n",
        "def res_image(image):\n",
        "  image = image.copy()\n",
        "  resize_image = cv2.resize(image, (256, 256),interpolation=cv2.INTER_NEAREST)\n",
        "  return resize_image"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGMnXyKXR-91"
      },
      "source": [
        "cropped_images = []\n",
        "n_crops = 1 #number of crops per image\n",
        "skip_factor = 1\n",
        "i = 1\n",
        "for _ in range (0,n_crops):\n",
        "  for img in images:\n",
        "    if i % skip_factor == 0:\n",
        "      crop_size = (int(img.shape[0]//4),int(img.shape[1]//4)) \n",
        "      cropped_images.append(res_image(random_crop(img,crop_size)))\n",
        "    i = i + 1  "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-kPbz81mHBc"
      },
      "source": [
        "cropped_images = np.asarray(cropped_images) \n",
        "if images.shape[0] + cropped_images.shape[0] < image_limit:\n",
        "  images = np.concatenate( (images, cropped_images) )"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4JwcA6im6ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a018455-54d0-4cef-edd4-e3ad44de39ef"
      },
      "source": [
        "images.shape[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hANHsQBR-91"
      },
      "source": [
        "### Rotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzOkiCmBR-92"
      },
      "source": [
        "def rotate_img(img, angle, bg_patch=(5,5)):\n",
        "    assert len(img.shape) <= 3, \"Incorrect image shape\"\n",
        "    rgb = len(img.shape) == 3\n",
        "    if rgb:\n",
        "        bg_color = np.mean(img[:bg_patch[0], :bg_patch[1], :], axis=(0,1))\n",
        "    else:\n",
        "        bg_color = np.mean(img[:bg_patch[0], :bg_patch[1]])\n",
        "    img = rotate(img, angle, reshape=False)\n",
        "    mask = [img <= 0, np.any(img <= 0, axis=-1)][rgb]\n",
        "    img[mask] = bg_color\n",
        "    return img"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R5QsFTeshf-"
      },
      "source": [
        "rotated_images = []\n",
        "n_rotations = 1 #number of rotated pictures per picture\n",
        "skip_factor = 1\n",
        "i = 1\n",
        "for _ in range (0,n_rotations):\n",
        "  for img in images:\n",
        "    if i % skip_factor == 0:\n",
        "      angle = np.random.randint(359)\n",
        "      rotated_images.append(rotate_img(img,angle))\n",
        "    i = i + 1"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqixfK9OtQb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdf3390-45cd-479b-876f-3a16ef10cc16"
      },
      "source": [
        "rotated_images = np.asarray(rotated_images)\n",
        "if images.shape[0] + rotated_images.shape[0] < image_limit:\n",
        "  images = np.concatenate((images, rotated_images))\n",
        "images.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S03fz8siR-92"
      },
      "source": [
        "### Random Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIRqUyYR-92"
      },
      "source": [
        "def gaussian_noise(img, mean=0, sigma=0.03):\n",
        "    img = img.copy()\n",
        "    noise = np.random.normal(mean, sigma, img.shape)\n",
        "    mask_overflow_upper = img+noise >= 1.0\n",
        "    mask_overflow_lower = img+noise < 0\n",
        "    noise[mask_overflow_upper] = 1.0\n",
        "    noise[mask_overflow_lower] = 0\n",
        "    img = img + noise\n",
        "    return img"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42lbQkwLuTnt"
      },
      "source": [
        "noised_images = []\n",
        "n_noises = 1\n",
        "skip_factor = 1 #due to high memory usage it's adviced to skip some images \n",
        "i = 1\n",
        "for _ in range (0,n_noises):\n",
        "  for img in images:\n",
        "    if i % skip_factor == 0:\n",
        "      sigma = round((np.random.randint(10)/121),2)\n",
        "      noised_images.append(gaussian_noise(img,sigma))\n",
        "\n",
        "    i = i + 1"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY2y1Yl1u1w0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeec89b6-5e2f-42bf-baae-77be8a735825"
      },
      "source": [
        "noised_images = np.asarray(noised_images)\n",
        "if images.shape[0] + noised_images.shape[0] < image_limit:\n",
        "  images = np.concatenate( (images, noised_images) )\n",
        "images.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdSb3SH1R-93"
      },
      "source": [
        "### Distortions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcmQ37a8R-93"
      },
      "source": [
        "def distort(img, orientation='horizontal', func=np.sin, x_scale=0.05, y_scale=5):\n",
        "    assert orientation[:3] in ['hor', 'ver'], \"dist_orient should be 'horizontal'|'vertical'\"\n",
        "    assert func in [np.sin, np.cos], \"supported functions are np.sin and np.cos\"\n",
        "    assert 0.00 <= x_scale <= 0.1, \"x_scale should be in [0.0, 0.1]\"\n",
        "    assert 0 <= y_scale <= min(img.shape[0], img.shape[1]), \"y_scale should be less then image size\"\n",
        "    img_dist = img.copy()\n",
        "    rgb = len(img.shape) == 3\n",
        "    def shift(x):\n",
        "        return int((y_scale * func(np.pi * x * x_scale)))\n",
        "    \n",
        "    if rgb:\n",
        "      for c in range(3):\n",
        "        for i in range(img.shape[orientation.startswith('ver')]):\n",
        "            if orientation.startswith('ver'):\n",
        "                img_dist[:, i, c] = np.roll(img[:, i, c], shift(i))   \n",
        "            else:\n",
        "                img_dist[i, :, c] = np.roll(img[i, :, c], shift(i))\n",
        "    else:\n",
        "         for i in range(img.shape[orientation.startswith('ver')]):\n",
        "            if orientation.startswith('ver'):\n",
        "                img_dist[:, i] = np.roll(img[:, i], shift(i))   \n",
        "            else:\n",
        "                img_dist[i, :] = np.roll(img[i, :], shift(i))        \n",
        "    return img_dist"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFuZTqaxzEtc"
      },
      "source": [
        "imgs_distorted = []\n",
        "skip_factor = 2\n",
        "i = 1\n",
        "\n",
        "for img in images:\n",
        "  for ori in ['ver', 'hor']:\n",
        "    if i % skip_factor == 0:\n",
        "      x_param = np.random.randint(1)/10\n",
        "      y_param = np.random.randint(min(img.shape[0], img.shape[1]) - np.random.randint(min(img.shape[0], img.shape[1])))\n",
        "      imgs_distorted.append(distort(img, orientation=ori, x_scale=x_param, y_scale=y_param))\n",
        "    i = i + 1 \n",
        "imgs_distorted = np.asarray(imgs_distorted)\n",
        "if images.shape[0] + imgs_distorted.shape[0] < image_limit:\n",
        "  images = np.concatenate((images, imgs_distorted))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj1nLVGUR-94"
      },
      "source": [
        "### Color channels change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bt5xu4BR-94"
      },
      "source": [
        "def change_channel_ratio(img, channel, ratio=0.5):\n",
        "    assert channel in 'rgb', \"Value for channel: rg|b|\"\n",
        "    img = img.copy()\n",
        "    ci = 'rgb'.index(channel)\n",
        "    img[:, :, ci] =  img[:, :, ci]*  ratio\n",
        "    return img"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hap5LGZi_wF0"
      },
      "source": [
        "colored_images = []\n",
        "n_colors = 1\n",
        "skip_factor = 2 #due to high memory usage it's adviced to skip some images \n",
        "i = 1\n",
        "rgb = len(img.shape) == 3\n",
        "if rgb:\n",
        "  for _ in range (0,n_colors):\n",
        "    for img in images:\n",
        "      if i % skip_factor == 0:\n",
        "        colors = ['r','g','b']\n",
        "        for color in colors:\n",
        "          sigma = round((np.random.randint(10)/135),2)\n",
        "          ratio = np.random.randint(10)/14\n",
        "          colored_images.append(change_channel_ratio(img,color,ratio))\n",
        "      i = i + 1"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHKheqroAsDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71264296-5afe-496c-d518-09b4fbfb1093"
      },
      "source": [
        "if rgb:\n",
        "  colored_images = np.asarray(colored_images)\n",
        "  if images.shape[0] + colored_images.shape[0] < image_limit:\n",
        "    images = np.concatenate((images, colored_images))\n",
        "images.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9B4C-wUR-94"
      },
      "source": [
        "def change_channel_ratio_gauss(img, channel='r', mean = 0, sigma=0.03):\n",
        "    assert channel in 'rgb', \"cahenel must be r|g|b\"\n",
        "    img = img.copy()\n",
        "    ci = 'rgb'.index(channel)\n",
        "    img[:, :, ci] = gaussian_noise(img[:, :, ci], mean=mean, sigma=sigma)\n",
        "    return img"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WETmHuPBHkK"
      },
      "source": [
        "colored_images = []\n",
        "n_colors = 1\n",
        "skip_factor = 1 #due to high memory usage it's adviced to skip some images \n",
        "\n",
        "i = 1\n",
        "rgb = len(img.shape) == 3\n",
        "if rgb:\n",
        "  for _ in range (0,n_colors):\n",
        "    for img in images:\n",
        "      if i % skip_factor == 0:\n",
        "        colors = ['r','g','b']\n",
        "        for color in colors:\n",
        "          mean = 0\n",
        "          sigma = np.random.randint(10)/40\n",
        "          colored_images.append(change_channel_ratio_gauss(img,color,0,sigma))\n",
        "      i = i + 1"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZqrAnZFBuSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfbab33-926c-4279-dc68-98ff0f930403"
      },
      "source": [
        "if rgb:\n",
        "  colored_images = np.asarray(colored_images)\n",
        "  if images.shape[0] + colored_images.shape[0] < image_limit:\n",
        "    images = np.concatenate((images, colored_images))\n",
        "images.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZPQQir1UH8k"
      },
      "source": [
        "import os\n",
        "save_path = destination_path\n",
        "i = 0\n",
        "for i in range(0,len(images)-1):\n",
        "  gen_img = Image.fromarray(images[i].astype(np.uint8))\n",
        "  file = 'grain_'+str(i+1)\n",
        "  gen_img.save(save_path+file+'.jpg')\n",
        "  i = i + 1 "
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppw_BeyfOjJN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}